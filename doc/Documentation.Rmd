---
title: "BEclearCL Documentation"
author: 
    - name: Livia Rasp
      affiliation:
        Center for Bioinformatics, Saarland University, Saarbruecken, Germany
      email: Livia.Rasp@gmail.com
date:  "`r Sys.Date()`"
abstract: |
  This command-line tool provides functions to detect and correct for batch effects in DNA methylation data. 
  The core function for the data imputation is based on latent factor models [@Candes2009] and can also be used to predict 
  missing values in any other matrix containing real numbers.
  In this documentation we guide you through the installation and usage of it. For the corresponding
  R-package visit `r BiocStyle::Biocpkg("BEclear")` [@Akulenko2016].
output: 
    BiocStyle::pdf_document:
      toc: FALSE
bibliography: "`r system.file('REFERENCES.bib', package = 'BEclear')`"
---

\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Getting Started

You have the choice to either download the latest tarball from https://github.com/uds-helms/BEclear-CL/archive/master.zip and expand it or clone the repository with the following command:

```{sh, eval = FALSE}
git clone git@github.com:uds-helms/BEclear-CL.git
```


For using the command-line version of BEclear, you need to have R with a version of at least 3.5 installed on your system.
Furthermore you need the following R packages:

  + `r BiocStyle::Biocpkg("BEclear")` (>= 2.0)
  + `r BiocStyle::CRANpkg("optparse")`
  
To install them you can either run our provided  `install_requirements.R` script or install them by typing the following in your R environment:

```{r, eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  
BiocManager::install("BEclear")

install.packages("optparse")
```

To make the command-line tool executable, you need to call:

```{sh, eval=FALSE}
chmod +x BEclearCL.R
```
\newpage


# Usage

## Example

The data-set used in this example is from The Cancer Genome Atlas [@TCGA].

```{sh, eval=FALSE}
./BEclearCL.R -f testDataSet.txt -o testImputed.txt -s testSamples.txt
```

## Parameters


In the following we will document the command-line parameters of the tool and the format of input and output.
The parameters will be explained consecutively:
  
  + -f _filename_, --file=_filename_
  
    Where _filename_ is the path to the input file containing a matrix with real numbers. 
    The matrix can already contain missing values, named `NA`.
    The features must be represented by the rows and the samples by columns. 
    For the columns the file has to contain a header. For the rows it can, but does not need 
    to contain an identifier in the first column. Columns have to be tab-seperated.
    
    If you do not set this parameter, BEclearCL expects this input from STDIN, so that it 
    can be integrated into pipelines.
    
  + -o _filename_, --out=_filename_
  
     Where _filename_ is the path where the output should be written to. 
     The format is the same as for the input. 
     
     If you do not set this parameter, BEclearCL prints the output to STDOUT.
  
  + -d, --detection
    
    If this parameter is set batch effects are detected. 
    Otherwise the tool only does the data imputation and expects 
    the input to already contain missing values, named `NA`.
    
  + -s _filename_ --samples=_filename_
    
    Where _filename_ is the path to the input file containing assignment of 
    samples to batches. It must contain a column named sample_id with the
    sample ID (same as in the input data) and one named batch_id with 
    the coresponding IDs for the batches.
    
    If this parameter is not provided each sample is tested against all other samples
    to find and correct for sample specific effects.
    
  + -c _number_, --cores=_number_
  
    Where _number_ represents the _number_ of cores you want the tool to use.
    It uses a snow backend for doing so.
    
  + -b _filename_, --BEscore=_filename_
  
    Where _filename_ is the path where the table containing the calculated
    batch scores should be written to.
    
    If not set, the file is not written.
    
  + -v, --verbose
    
    If set, the tool will write output about its progress to the STDOUT.
    By default it does not.
    
  + -r, --replace
  
    If values outside of the interval between 0 and 1 should be cropped to 0 or 1,
    which can be necessary depending on your type of data. 
    For example for DNA methylation data.
    
    By default this is not done. 
    

# Theoretical Background

In this section we explain the theoretical background behind the method.

## Detection of batch effects

For the detection of batch effects we calculate the median difference between the 
beta values of a gene in a batch and the values of this gene in all other batches. 
Furthermore we use a non-parametric Kolmogorov-Smirnov test (`ks.test`) to  compare the
distribution of the beta value for this gene in the batch and the other batches.

If one gene in a batch has a p-value determined by the `ks.test` of less or equal
0.01 and a median difference of greater or equal 0.05 it is considered batch effected.
By default the p-values are adjusted by the false discovery rate developed by @BH.

## Imputation of missing values

For the imputation of missing values we use a slightly modified version of the
stochastic gradient descent method described by @Koren2009. 
In this section we will describe our implementation of this method and how to 
use it.


We assume that our complete data matrix \(D_{ij}\) can be described by the effects of
a matrix \(L_i\), which represents the effect of the features (genes in our case)
and a matrix \(R_j\) describing the effect of the samples in the following way:

\begin{equation}
D_{ij} = L_{i}^{T} \times R_{j}.
(\#eq:assumption)
\end{equation}

The method can either be run on the complete data set or the data set can be 
divided into blocks on which the method is applied.
This division into blocks allows for parallelisation of the method, which can be 
useful to speed up the process. We have found that a block-size of 60x60 works 
well[@Akulenko2016].

The error for each block is calculated in the following way:

\begin{equation}
  errorMatrix_{ij} = Block_{ij} - L_{i}^{T} \times R_{j}.
  (\#eq:errormatrix)
\end{equation}

We try to minimize the following loss function through a gradient descent:

\begin{equation}
  min_{L, R}  \sum_{ij \in K}(errorMatrix_{ij}^2) + \lambda \times
  (\left\lVert L_{i}\right\rVert_{F}^{2} + 
  \left\lVert R_{j}\right\rVert_{F}^{2} ).
  (\#eq:loss)
\end{equation}
Where \(K\) is the set of tuples \((i,j)\) for which the value is present. 
\(\lambda\) is the penalty coefficient, which controls how restrictive the 
selection of variables should be. The default of \(\lambda\) is 1.

Another coefficient \(\gamma\) controls the size of the step by which the 
two matrices \(L_i\) and \(R_j\) are modified. It is initialized 
by default with 0.01 and its value changes during the iterations (epochs).

For the first iteration the matrices \(L_i\) and \(R_j\) are filled with random values
generated by the `rnorm` function from the `r BiocStyle::Rpackage("stats")` 
package and the initial loss and error matrix are calculated.

Then for each iteration the following is done:
    
* \(L_i\) and \(R_j\) are modified proportional by \(\gamma\) through the following 
calculation:

    + \begin{equation}
      L_i = L_i + 2 \times \gamma \times  (errorMatrix_{ij} \times R_j - \lambda \times L_i).
      (\#eq:Lmod)
      \end{equation}

    + \begin{equation}
      R_j = R_j + 2 \times \gamma \times (errorMatrix_{ij} \times L_i - \lambda \times R_j).
      (\#eq:Rmod)
      \end{equation}

* Then the new error matrix and loss are calculated.
* If the old loss is smaller than the new one: 
    + \(\gamma = \gamma \div 2.\)
* Else:
    + \(\gamma = \gamma \times 1.05.\)
    
The \(L_i\) and \(R_j\) matrices at the end of the last iteration are then used to 
impute the missing data. The default number of iterations is 50.


# References {.unnumbered}
